# Pre-training Configuration

# Dataset
dataset_type: "sensor"

sensor_data:
  # データセットの基本設定
  data_root: "har-unified-dataset/data/processed"  # データルートディレクトリ
  datasets: ["nhanes"]  # 使用するデータセット名

  # バッチローダー設定
  batch_loader:
    exclude_patterns: []  # 除外パターン（例: ["USER00001"]）
    sample_threshold: 1000  # 最小サンプル数（1ファイルあたり）
    batch_size: 4  # 1バッチに含める被験者（ファイル）数
    train_num_samples: 1000  # エポックあたりのサンプル数
    val_num_samples: 100
    test_num_samples: 100

# Model
model:
  name: "resnet"
  backbone: "resnet"
  feature_dim: 256
  projection_dim: 128

# Multitask Learning
multitask:
  enabled: true
  # SSLタスクの設定
  # - binary_*: 変換予測タスク（binary_permute, binary_reverse, binary_timewarp）
  # - masking_*: マスク再構成タスク（masking_channel, masking_time, masking_time_channel）
  # - contrastive_*: 対照学習タスク（将来拡張用）
  ssl_tasks: ["binary_permute", "binary_reverse", "binary_timewarp"]
  task_weights: [1.0, 1.0, 1.0]
  apply_prob: 0.5  # binary_*タスクの適用確率
  mask_ratio: 0.15  # masking_*タスクのマスク比率

# Data Augmentation
augmentation:
  enabled: false  # データ拡張を無効化（シンプル化のため）
  # mode: "mtl"  # light, medium, heavy, mtl

# Training
training:
  epochs: 100
  learning_rate: 0.001
  weight_decay: 0.0001
  optimizer: "adam"
  scheduler: "cosine"
  warmup_epochs: 10
  grad_clip_norm: 1.0  # 勾配クリッピング（1.0推奨、無効化する場合はnull）

# Hardware
device: "cuda:0"
mixed_precision: true

# Checkpointing
checkpoint:
  save_freq: 10

# Early Stopping
early_stopping:
  enabled: false  # Early Stoppingを有効化（長時間学習時に推奨）
  patience: 20    # 改善が見られないエポック数
  min_delta: 0.001  # 改善と見なす最小変化量

# Logging
logging:
  log_interval: 10
  log_dir: "logs/pretrain"

# Weights & Biases
wandb:
  enabled: true
  project: "har-foundation"
  tags: ["pretrain", "multitask"]

# Seed
seed: 42

# Grid Search
grid_search:
  multitask:
    ssl_tasks:
      - ["binary_permute", "binary_reverse", "binary_timewarp"]
      - ["binary_permute", "binary_reverse", "binary_timewarp", "masking_time_channel"]
      - ["masking_time_channel"]

settings:
  stop_on_error: false
  save_summary: true
  summary_path: "logs/pretrain_experiments_summary.json"
  parallel: true  # GPU並列実行
  max_workers: null  # null=利用可能なGPU全て、数値=最大並列数
