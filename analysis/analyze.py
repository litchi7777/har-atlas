#!/usr/bin/env python3
"""
HAR Foundation - çµ±ä¸€åˆ†æã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ã™ã¹ã¦ã®åˆ†ææ©Ÿèƒ½ã¸ã®çµ±ä¸€ã•ã‚ŒãŸã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æä¾›ã—ã¾ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
    python analysis/analyze.py <analysis_type> [options]

åˆ†æã‚¿ã‚¤ãƒ—:
    data          - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å¸ƒã¨å“è³ªåˆ†æ
    embeddings    - ç‰¹å¾´ç©ºé–“ã®å¯è¦–åŒ–ï¼ˆt-SNE/UMAPï¼‰
    performance   - ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®è©³ç´°åˆ†æ
    features      - ç‰¹å¾´é‡ã®è©³ç´°åˆ†æ
    all           - å…¨åˆ†æã‚’å®Ÿè¡Œ

ä¾‹:
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†æ
    python analysis/analyze.py data --dataset dsads --location Torso

    # ç‰¹å¾´ç©ºé–“ã®å¯è¦–åŒ–
    python analysis/analyze.py embeddings \\
      --model experiments/pretrain/run_*/exp_0/models/best_model.pth

    # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½åˆ†æ
    python analysis/analyze.py performance \\
      --experiment experiments/finetune/run_*/exp_0

    # å…¨åˆ†æã‚’å®Ÿè¡Œ
    python analysis/analyze.py all \\
      --model experiments/pretrain/run_*/exp_0/models/best_model.pth \\
      --experiment experiments/finetune/run_*/exp_0
"""

import sys
import argparse
from pathlib import Path

# å„åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import dataset_distribution
import data_quality
import visualize_embeddings
import model_performance
import feature_analysis


def run_data_analysis(args):
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å¸ƒã¨å“è³ªåˆ†æã‚’å®Ÿè¡Œ"""
    print("\n" + "="*80)
    print("ğŸ“Š DATA ANALYSIS")
    print("="*80)

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å¸ƒåˆ†æ
    if args.distribution or args.all_data:
        print("\n--- Dataset Distribution Analysis ---")
        dist_args = argparse.Namespace(
            dataset=args.dataset,
            location=args.location,
            all=args.all_data,
            compare=args.compare
        )
        dataset_distribution.main_with_args(dist_args)

    # ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æ
    if args.quality or args.all_data:
        print("\n--- Data Quality Analysis ---")
        quality_args = argparse.Namespace(
            dataset=args.dataset,
            location=args.location,
            datasets=args.datasets,
            all=args.all_data,
            compare=args.compare
        )
        data_quality.main_with_args(quality_args)


def run_embeddings_analysis(args):
    """ç‰¹å¾´ç©ºé–“ã®å¯è¦–åŒ–ã‚’å®Ÿè¡Œ"""
    print("\n" + "="*80)
    print("ğŸ—ºï¸  EMBEDDINGS ANALYSIS")
    print("="*80)

    embed_args = argparse.Namespace(
        model=args.model,
        models=args.models,
        method=args.method,
        color_by=args.color_by,
        datasets=args.datasets,
        locations=args.locations,
        max_samples=args.max_samples,
        device=args.device
    )
    visualize_embeddings.main_with_args(embed_args)


def run_performance_analysis(args):
    """ãƒ¢ãƒ‡ãƒ«æ€§èƒ½åˆ†æã‚’å®Ÿè¡Œ"""
    print("\n" + "="*80)
    print("ğŸ“ˆ PERFORMANCE ANALYSIS")
    print("="*80)

    perf_args = argparse.Namespace(
        experiment=args.experiment,
        experiments=args.experiments,
        compare=args.compare,
        mode=args.mode
    )
    model_performance.main_with_args(perf_args)


def run_features_analysis(args):
    """ç‰¹å¾´é‡ã®è©³ç´°åˆ†æã‚’å®Ÿè¡Œ"""
    print("\n" + "="*80)
    print("ğŸ”¬ FEATURE ANALYSIS")
    print("="*80)

    feat_args = argparse.Namespace(
        model=args.model,
        models=args.models,
        datasets=args.datasets,
        locations=args.locations,
        max_samples=args.max_samples,
        device=args.device,
        compare=args.compare
    )
    feature_analysis.main_with_args(feat_args)


def run_all_analyses(args):
    """å…¨åˆ†æã‚’å®Ÿè¡Œ"""
    print("\n" + "="*80)
    print("ğŸš€ RUNNING ALL ANALYSES")
    print("="*80)

    # ãƒ‡ãƒ¼ã‚¿åˆ†æ
    if args.dataset or args.all_data:
        run_data_analysis(args)

    # ç‰¹å¾´ç©ºé–“ã®å¯è¦–åŒ–
    if args.model or args.models:
        run_embeddings_analysis(args)

    # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½åˆ†æ
    if args.experiment or args.experiments:
        run_performance_analysis(args)

    # ç‰¹å¾´é‡åˆ†æ
    if args.model or args.models:
        run_features_analysis(args)

    print("\n" + "="*80)
    print("âœ… ALL ANALYSES COMPLETED")
    print("="*80)


def main():
    parser = argparse.ArgumentParser(
        description='HAR Foundation - çµ±ä¸€åˆ†æã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†æ
  python analysis/analyze.py data --dataset dsads --location Torso

  # ç‰¹å¾´ç©ºé–“ã®å¯è¦–åŒ–
  python analysis/analyze.py embeddings \\
    --model experiments/pretrain/run_*/exp_0/models/best_model.pth

  # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½åˆ†æ
  python analysis/analyze.py performance \\
    --experiment experiments/finetune/run_*/exp_0

  # ç‰¹å¾´é‡åˆ†æ
  python analysis/analyze.py features \\
    --model experiments/pretrain/run_*/exp_0/models/best_model.pth

  # å…¨åˆ†æã‚’å®Ÿè¡Œ
  python analysis/analyze.py all \\
    --model experiments/pretrain/run_*/exp_0/models/best_model.pth \\
    --experiment experiments/finetune/run_*/exp_0 \\
    --dataset dsads --location Torso
        """
    )

    # ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰
    subparsers = parser.add_subparsers(dest='analysis_type', help='åˆ†æã‚¿ã‚¤ãƒ—')

    # ===== ãƒ‡ãƒ¼ã‚¿åˆ†æ =====
    data_parser = subparsers.add_parser('data', help='ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å¸ƒã¨å“è³ªåˆ†æ')
    data_parser.add_argument('--dataset', type=str, help='ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå')
    data_parser.add_argument('--location', type=str, help='èº«ä½“éƒ¨ä½')
    data_parser.add_argument('--datasets', nargs='+', help='è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ')
    data_parser.add_argument('--all-data', action='store_true', help='å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ†æ')
    data_parser.add_argument('--compare', action='store_true', help='ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé–“ã®æ¯”è¼ƒ')
    data_parser.add_argument('--distribution', action='store_true', default=True,
                             help='åˆ†å¸ƒåˆ†æã‚’å®Ÿè¡Œ')
    data_parser.add_argument('--quality', action='store_true', default=True,
                             help='å“è³ªåˆ†æã‚’å®Ÿè¡Œ')

    # ===== ç‰¹å¾´ç©ºé–“ã®å¯è¦–åŒ– =====
    embed_parser = subparsers.add_parser('embeddings', help='ç‰¹å¾´ç©ºé–“ã®å¯è¦–åŒ–')
    embed_parser.add_argument('--model', type=str, help='ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹')
    embed_parser.add_argument('--models', nargs='+', help='è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ï¼ˆæ¯”è¼ƒç”¨ï¼‰')
    embed_parser.add_argument('--method', type=str, default='umap',
                              choices=['umap', 'tsne'], help='æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•')
    embed_parser.add_argument('--color-by', type=str, default='body_part',
                              choices=['dataset', 'body_part', 'dataset_location'],
                              help='è‰²åˆ†ã‘åŸºæº–')
    embed_parser.add_argument('--datasets', nargs='+', help='å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ')
    embed_parser.add_argument('--locations', nargs='+', help='å¯¾è±¡èº«ä½“éƒ¨ä½')
    embed_parser.add_argument('--max-samples', type=int, default=500,
                              help='å„ã‚¯ãƒ©ã‚¹ã®æœ€å¤§ã‚µãƒ³ãƒ—ãƒ«æ•°')
    embed_parser.add_argument('--device', type=str, default='cuda',
                              help='ãƒ‡ãƒã‚¤ã‚¹ (cuda/cpu)')

    # ===== ãƒ¢ãƒ‡ãƒ«æ€§èƒ½åˆ†æ =====
    perf_parser = subparsers.add_parser('performance', help='ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®è©³ç´°åˆ†æ')
    perf_parser.add_argument('--experiment', type=str, help='å®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹')
    perf_parser.add_argument('--experiments', nargs='+', help='è¤‡æ•°ã®å®Ÿé¨“ï¼ˆæ¯”è¼ƒç”¨ï¼‰')
    perf_parser.add_argument('--compare', action='store_true', help='å®Ÿé¨“é–“ã®æ¯”è¼ƒ')
    perf_parser.add_argument('--mode', type=str, default='finetune',
                             choices=['pretrain', 'finetune'], help='å®Ÿé¨“ãƒ¢ãƒ¼ãƒ‰')

    # ===== ç‰¹å¾´é‡åˆ†æ =====
    feat_parser = subparsers.add_parser('features', help='ç‰¹å¾´é‡ã®è©³ç´°åˆ†æ')
    feat_parser.add_argument('--model', type=str, help='ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹')
    feat_parser.add_argument('--models', nargs='+', help='è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ï¼ˆæ¯”è¼ƒç”¨ï¼‰')
    feat_parser.add_argument('--datasets', nargs='+', help='å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ')
    feat_parser.add_argument('--locations', nargs='+', help='å¯¾è±¡èº«ä½“éƒ¨ä½')
    feat_parser.add_argument('--max-samples', type=int, default=1000,
                              help='åˆ†æç”¨ã®æœ€å¤§ã‚µãƒ³ãƒ—ãƒ«æ•°')
    feat_parser.add_argument('--device', type=str, default='cuda',
                              help='ãƒ‡ãƒã‚¤ã‚¹ (cuda/cpu)')
    feat_parser.add_argument('--compare', action='store_true', help='ãƒ¢ãƒ‡ãƒ«é–“ã®æ¯”è¼ƒ')

    # ===== å…¨åˆ†æ =====
    all_parser = subparsers.add_parser('all', help='å…¨åˆ†æã‚’å®Ÿè¡Œ')
    all_parser.add_argument('--model', type=str, help='ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹')
    all_parser.add_argument('--models', nargs='+', help='è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹')
    all_parser.add_argument('--experiment', type=str, help='å®Ÿé¨“ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹')
    all_parser.add_argument('--experiments', nargs='+', help='è¤‡æ•°ã®å®Ÿé¨“')
    all_parser.add_argument('--dataset', type=str, help='ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå')
    all_parser.add_argument('--location', type=str, help='èº«ä½“éƒ¨ä½')
    all_parser.add_argument('--datasets', nargs='+', help='å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ')
    all_parser.add_argument('--locations', nargs='+', help='å¯¾è±¡èº«ä½“éƒ¨ä½')
    all_parser.add_argument('--all-data', action='store_true', help='å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ†æ')
    all_parser.add_argument('--compare', action='store_true', help='æ¯”è¼ƒåˆ†æã‚’æœ‰åŠ¹åŒ–')
    all_parser.add_argument('--method', type=str, default='umap',
                            choices=['umap', 'tsne'], help='æ¬¡å…ƒå‰Šæ¸›æ‰‹æ³•')
    all_parser.add_argument('--color-by', type=str, default='body_part',
                            choices=['dataset', 'body_part', 'dataset_location'],
                            help='è‰²åˆ†ã‘åŸºæº–')
    all_parser.add_argument('--max-samples', type=int, default=500,
                            help='æœ€å¤§ã‚µãƒ³ãƒ—ãƒ«æ•°')
    all_parser.add_argument('--device', type=str, default='cuda',
                            help='ãƒ‡ãƒã‚¤ã‚¹ (cuda/cpu)')
    all_parser.add_argument('--mode', type=str, default='finetune',
                            choices=['pretrain', 'finetune'], help='å®Ÿé¨“ãƒ¢ãƒ¼ãƒ‰')
    all_parser.add_argument('--distribution', action='store_true', default=True)
    all_parser.add_argument('--quality', action='store_true', default=True)

    args = parser.parse_args()

    # ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆ
    if not args.analysis_type:
        parser.print_help()
        sys.exit(1)

    # åˆ†æã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦å®Ÿè¡Œ
    if args.analysis_type == 'data':
        run_data_analysis(args)
    elif args.analysis_type == 'embeddings':
        run_embeddings_analysis(args)
    elif args.analysis_type == 'performance':
        run_performance_analysis(args)
    elif args.analysis_type == 'features':
        run_features_analysis(args)
    elif args.analysis_type == 'all':
        run_all_analyses(args)


if __name__ == '__main__':
    main()
